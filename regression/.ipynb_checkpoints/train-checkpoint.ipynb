{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From ../core/common.py:52: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "=>Restore weights from /hdd/sd5/tlc/pretrain_model/darknet53/yolov3_test_loss=136.5372.ckpt-80\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /hdd/sd5/tlc/pretrain_model/darknet53/yolov3_test_loss=136.5372.ckpt-80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/494 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/sd5/tlc/pretrain_model/darknet53/yolov3_test_loss=136.5372.ckpt-80does not exist!\n",
      "=>starts training from scratch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 5.79: 100%|██████████| 494/494 [01:20<00:00,  6.10it/s] \n",
      "train loss: 1.82:   0%|          | 1/494 [00:00<01:11,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Train loss: 4.79\n",
      "Test loss: 20.66 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.60: 100%|██████████| 494/494 [01:11<00:00,  6.87it/s] \n",
      "train loss: 5.94:   0%|          | 1/494 [00:00<01:17,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Train loss: 3.54\n",
      "Test loss: 10.75 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.75: 100%|██████████| 494/494 [01:12<00:00,  6.84it/s] \n",
      "train loss: 1.48:   0%|          | 1/494 [00:00<01:22,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2 Train loss: 3.10\n",
      "Test loss: 4.58 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.57: 100%|██████████| 494/494 [01:11<00:00,  6.86it/s] \n",
      "train loss: 2.61:   0%|          | 1/494 [00:00<01:20,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3 Train loss: 2.93\n",
      "Test loss: 6.21 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.47: 100%|██████████| 494/494 [01:11<00:00,  6.90it/s] \n",
      "train loss: 5.79:   0%|          | 1/494 [00:00<01:23,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4 Train loss: 3.12\n",
      "Test loss: 2.69 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.48: 100%|██████████| 494/494 [01:11<00:00,  6.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Train loss: 2.66\n",
      "Test loss: 3.21 \n",
      "WARNING:tensorflow:From <ipython-input-1-05e0bbee27e8>:135: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 89 variables.\n",
      "INFO:tensorflow:Converted 89 variables to const ops.\n",
      "WARNING:tensorflow:From <ipython-input-1-05e0bbee27e8>:139: __init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.79: 100%|██████████| 494/494 [01:18<00:00,  6.29it/s] \n",
      "train loss: 0.88:   0%|          | 1/494 [00:00<01:21,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6 Train loss: 2.58\n",
      "Test loss: 11.11 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.37: 100%|██████████| 494/494 [01:11<00:00,  6.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7 Train loss: 2.34\n",
      "Test loss: 2.82 \n",
      "INFO:tensorflow:Froze 89 variables.\n",
      "INFO:tensorflow:Converted 89 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.86: 100%|██████████| 494/494 [01:10<00:00,  6.99it/s] \n",
      "train loss: 3.01:   0%|          | 1/494 [00:00<01:13,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 Train loss: 2.38\n",
      "Test loss: 2.70 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.95: 100%|██████████| 494/494 [01:09<00:00,  7.09it/s] \n",
      "train loss: 3.45:   0%|          | 1/494 [00:00<01:05,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9 Train loss: 2.23\n",
      "Test loss: 3.09 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.14: 100%|██████████| 494/494 [01:08<00:00,  7.26it/s] \n",
      "train loss: 1.16:   0%|          | 1/494 [00:00<01:13,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train loss: 2.12\n",
      "Test loss: 2.89 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.88: 100%|██████████| 494/494 [01:07<00:00,  7.32it/s] \n",
      "train loss: 0.65:   0%|          | 1/494 [00:00<01:05,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Train loss: 2.12\n",
      "Test loss: 2.94 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.52: 100%|██████████| 494/494 [01:07<00:00,  7.31it/s]\n",
      "train loss: 2.42:   0%|          | 1/494 [00:00<01:16,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Train loss: 1.99\n",
      "Test loss: 10.63 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.21: 100%|██████████| 494/494 [01:07<00:00,  7.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Train loss: 1.95\n",
      "Test loss: 2.55 \n",
      "INFO:tensorflow:Froze 89 variables.\n",
      "INFO:tensorflow:Converted 89 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.03: 100%|██████████| 494/494 [01:06<00:00,  7.48it/s] \n",
      "train loss: 2.75:   0%|          | 1/494 [00:00<00:59,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Train loss: 1.90\n",
      "Test loss: 3.60 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.59: 100%|██████████| 494/494 [01:07<00:00,  7.29it/s] \n",
      "train loss: 1.98:   0%|          | 1/494 [00:00<01:03,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Train loss: 1.84\n",
      "Test loss: 2.92 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.10: 100%|██████████| 494/494 [01:07<00:00,  7.31it/s] \n",
      "train loss: 1.00:   0%|          | 1/494 [00:00<01:13,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Train loss: 1.80\n",
      "Test loss: 3.79 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.37: 100%|██████████| 494/494 [01:07<00:00,  7.31it/s]\n",
      "train loss: 1.07:   0%|          | 1/494 [00:00<01:13,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Train loss: 1.77\n",
      "Test loss: 5.74 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.09: 100%|██████████| 494/494 [01:07<00:00,  7.33it/s] \n",
      "train loss: 2.51:   0%|          | 1/494 [00:00<00:59,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Train loss: 1.72\n",
      "Test loss: 9.32 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.26: 100%|██████████| 494/494 [01:07<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Train loss: 1.82\n",
      "Test loss: 2.15 \n",
      "INFO:tensorflow:Froze 89 variables.\n",
      "INFO:tensorflow:Converted 89 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.07: 100%|██████████| 494/494 [01:07<00:00,  7.28it/s]\n",
      "train loss: 0.85:   0%|          | 1/494 [00:00<01:06,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Train loss: 1.70\n",
      "Test loss: 4.08 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.28: 100%|██████████| 494/494 [01:07<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 Train loss: 1.62\n",
      "Test loss: 2.15 \n",
      "INFO:tensorflow:Froze 89 variables.\n",
      "INFO:tensorflow:Converted 89 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.29: 100%|██████████| 494/494 [01:08<00:00,  7.23it/s]\n",
      "train loss: 3.44:   0%|          | 1/494 [00:00<01:02,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Train loss: 1.59\n",
      "Test loss: 2.22 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.03: 100%|██████████| 494/494 [01:06<00:00,  7.41it/s]\n",
      "train loss: 1.47:   0%|          | 1/494 [00:00<01:01,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 Train loss: 1.53\n",
      "Test loss: 2.44 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.97: 100%|██████████| 494/494 [01:06<00:00,  7.40it/s]\n",
      "train loss: 0.69:   0%|          | 1/494 [00:00<01:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 Train loss: 1.51\n",
      "Test loss: 2.40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.54: 100%|██████████| 494/494 [01:07<00:00,  7.35it/s]\n",
      "train loss: 0.99:   0%|          | 1/494 [00:00<01:25,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 Train loss: 1.52\n",
      "Test loss: 4.99 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 0.81: 100%|██████████| 494/494 [01:07<00:00,  7.34it/s]\n",
      "train loss: 2.08:   0%|          | 1/494 [00:00<01:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Train loss: 1.47\n",
      "Test loss: 2.63 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.26: 100%|██████████| 494/494 [01:06<00:00,  7.40it/s]\n",
      "train loss: 2.04:   0%|          | 1/494 [00:00<01:15,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 Train loss: 1.57\n",
      "Test loss: 6.62 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.67:  26%|██▌       | 128/494 [00:17<00:51,  7.05it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05e0bbee27e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-05e0bbee27e8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-05e0bbee27e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_scale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                                                          })\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "from config_reg import cfg\n",
    "from dataset import Dataset\n",
    "from factory_reg import backbone\n",
    "from random import randint\n",
    "from tensorflow.python.framework import graph_util\n",
    "import pandas as pd\n",
    "\n",
    "class Regression(object):\n",
    "    def __init__(self):\n",
    "        self.Batch_Size = cfg.TRAIN.BATCHSIZE\n",
    "        self.learn_rate_init = cfg.TRAIN.LEARN_RATE_INIT\n",
    "        self.num_classes = cfg.TRAIN.REG_NUM\n",
    "        self.trainset = Dataset(self.num_classes,'train')\n",
    "        self.testset = Dataset(self.num_classes,'test')\n",
    "        self.network = cfg.TRAIN.NETWORK\n",
    "        self.train_txt = cfg.TRAIN.ANNO_PATH\n",
    "        self.sess = tf.Session()\n",
    "        self.model_type = cfg.TRAIN.NETWORK\n",
    "        self.input_size = cfg.TRAIN.INPUTSIZE\n",
    "        self.interval = cfg.TRAIN.SAVE\n",
    "        #self.excel_path = './result.xlsx'\n",
    "        #self.df = pd.DataFrame(columns=['Source', 'Quantity', 'Model_name', 'Epoch', 'Loss', 'Acc'])\n",
    "        self.initial_weights = cfg.TRAIN.INITIAL_WEIGHT\n",
    "        self.pretrain_mode = cfg.TRAIN.PRETRAIN_MODE\n",
    "        self.epoch = cfg.TRAIN.EPOCH\n",
    "        self.pretrain_model = cfg.TRAIN.BACKBONE_PRETRAIN\n",
    "        self.moving_ave_decay = cfg.TRAIN.MOMENTUM\n",
    "        self.save_path_ckpt = cfg.TRAIN.SAVE_PATH_CKPT\n",
    "        self.save_path_pb = cfg.TRAIN.SAVE_PATH_PB\n",
    "        self.quantity = len(open(self.train_txt, 'r').readlines())\n",
    "        self.source = ''\n",
    "        #self.get_src()\n",
    "        self.keep_prob = tf.placeholder(dtype=tf.float32, name='dropout')\n",
    "        #self.writer = pd.ExcelWriter(self.excel_path)\n",
    "        self.moving_ave_decay = 0.995\n",
    "        \n",
    "       \n",
    "        self.input_data = tf.placeholder(shape = [None, self.input_size, self.input_size, 3], dtype=tf.float32, name='input')\n",
    "        self.input_labels = tf.placeholder(shape = [None, self.num_classes], dtype=tf.float32, name='label')\n",
    "        self.input_scale = tf.placeholder(shape = [None, 1], dtype=tf.float32, name='scale')\n",
    "        self.trainable = tf.placeholder(dtype=tf.bool, name='trainable')\n",
    "\n",
    "        \n",
    "        self.model = backbone(model=self.network, input_data=self.input_data, trainable=self.trainable, classes=self.num_classes, keep_prob=1.0, scale=self.input_scale)\n",
    "        self.loss = self.model.compute_loss(labels=self.input_labels)\n",
    "        self.net_var = tf.trainable_variables()\n",
    "        self.varaibles_to_restore = [var for var in self.net_var if 'backbone' in var.name]\n",
    "        \n",
    "            \n",
    "        #moving_ave = tf.train.ExponentialMovingAverage(self.moving_ave_decay).apply(tf.trainable_variables())\n",
    "        self.global_step = tf.Variable(1.0, dtype=tf.float32, trainable=False, name='global_step')\n",
    "        self.global_step_update = tf.assign_add(self.global_step, 1.0)\n",
    "        self.optimizer =  tf.train.AdamOptimizer(self.learn_rate_init).minimize(self.loss, var_list=self.net_var)\n",
    "        #self.optimizer = tf.train.MomentumOptimizer(learning_rate=self.learn_rate_init, momentum=0.8).minimize(self.loss)\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            with tf.control_dependencies([self.optimizer, self.global_step_update]):\n",
    "                #with tf.control_dependencies([moving_ave]):\n",
    "                self.train_op = tf.no_op()\n",
    "        \n",
    "            #self.optimizer = tf.train.MomentumOptimizer(learning_rate=self.learn_rate_init, momentum=0.8).minimize(self.loss)\n",
    "        \n",
    "        self.loader_backbone = tf.train.Saver(self.varaibles_to_restore)\n",
    "        self.loader_whole = tf.train.Saver(tf.global_variables())\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=10)\n",
    "        \n",
    "        \n",
    "#         tensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]\n",
    "#         for tensor_name in tensor_name_list:\n",
    "#             print(tensor_name,'\\n')\n",
    "\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        #self.sess.run(tf.global_variables_initializer())\n",
    "        if self.pretrain_mode == 'whole':\n",
    "            try:\n",
    "                print ('=>Restore weights from ' + self.initial_weights)\n",
    "                self.loader_whole.restore(self.sess, self.initial_weights)\n",
    "            except:\n",
    "                print (self.initial_weights + 'does not exist!')\n",
    "                print ('=>starts training from scratch ...')\n",
    "        else:\n",
    "            try:\n",
    "                print ('=>Restore weights from ' + self.pretrain_model)\n",
    "                self.loader_backbone.restore(self.sess, self.pretrain_model)\n",
    "            except:\n",
    "                print (self.pretrain_model + 'does not exist!')\n",
    "                print ('=>starts training from scratch ...')\n",
    "        \n",
    "        min_loss_val = 20\n",
    "        min_loss_train = 20\n",
    "        i = 0\n",
    "        for epoch in range(self.epoch):\n",
    "            pabr = tqdm(self.trainset)\n",
    "            train_epoch_loss, test_epoch_loss = [], []\n",
    "            #train_epoch_acc, test_epoch_acc = [], []\n",
    "            for train_data in pabr:\n",
    "                _, train_step_loss = self.sess.run([self.train_op, self.loss], feed_dict={self.input_data: train_data[0],\n",
    "                                                         self.input_labels: train_data[1],\n",
    "                                                         self.input_scale: train_data[2],\n",
    "                                                         self.trainable: True,\n",
    "                                                         })\n",
    "                \n",
    "                train_epoch_loss.append(train_step_loss)\n",
    "                #train_epoch_acc.append(train_step_acc)\n",
    "                pabr.set_description(\"train loss: %.2f\" %train_step_loss)\n",
    "            \n",
    "            for test_data in self.testset:\n",
    "                test_step_loss = self.sess.run([self.loss],\n",
    "                                                                feed_dict={self.input_data: test_data[0],\n",
    "                                                                           self.input_labels: test_data[1],\n",
    "                                                                           self.input_scale: test_data[2],\n",
    "                                                                           self.trainable: False, \n",
    "                                                                           })\n",
    "\n",
    "                test_epoch_loss.append(test_step_loss)\n",
    "                #test_epoch_acc.append(test_step_acc)\n",
    "\n",
    "            train_epoch_loss, test_epoch_loss = np.mean(train_epoch_loss), np.mean(test_epoch_loss)\n",
    "            print ('Epoch: %2d Train loss: %.2f'\n",
    "                   %(epoch, train_epoch_loss))\n",
    "\n",
    "            print ('Test loss: %.2f '\n",
    "                   % (test_epoch_loss))\n",
    "            \n",
    "            \n",
    "            if epoch >= 5 and test_epoch_loss < min_loss_val and train_epoch_loss < min_loss_train:\n",
    "                min_loss_val = test_epoch_loss\n",
    "                min_loss_train = train_epoch_loss\n",
    "                constant_graph = graph_util.convert_variables_to_constants(self.sess, self.sess.graph_def, ['fc_layer/op_to_store'])\n",
    "                model_name = self.model_type+'_epoch=%d' %epoch\n",
    "                ckpt_file = self.save_path_ckpt + model_name + '_test_loss=%.4f.ckpt' %test_epoch_loss\n",
    "                #self.saver.save(self.sess, ckpt_file, global_step=epoch)\n",
    "                with tf.gfile.FastGFile(self.save_path_pb + model_name+'.pb', mode='wb') as f:\n",
    "                    f.write(constant_graph.SerializeToString())\n",
    "#                 self.df.loc[i] = [randint(-1, 1) for _ in range(len(self.df.columns))]\n",
    "#                 self.df.iloc[i,0] = self.source\n",
    "#                 self.df.iloc[i,1] = str(self.quantity)\n",
    "#                 self.df.iloc[i,2] = model_name\n",
    "#                 self.df.iloc[i,3] = str(epoch)\n",
    "#                 self.df.iloc[i,4] = str(test_epoch_loss)\n",
    "#                 self.df.iloc[i,5] = str(test_epoch_acc)\n",
    "#                 i += 1\n",
    "                \n",
    "                \n",
    "#         self.df.to_excel(self.writer, 'Sheet1')\n",
    "#         self.writer.save()\n",
    "                \n",
    "\n",
    "    def main(self):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.train()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    Regression().main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
